import { useState, useRef, useEffect, useCallback } from 'react'
import { getFurigana, speak } from '../utils/japanese'

export default function CameraMode({ deeplKey, onBack }) {
  const [isStreaming, setIsStreaming] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [capturedImage, setCapturedImage] = useState(null);
  const [results, setResults] = useState([]);
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const streamRef = useRef(null);

  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'environment',
          width: { ideal: 1920 },
          height: { ideal: 1080 },
          zoom: { ideal: 2 },
        },
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
      streamRef.current = stream;
      setIsStreaming(true);
      setCapturedImage(null);
      setResults([]);
    } catch (err) {
      console.error('Camera error:', err);
      alert('ã‚«ãƒ¡ãƒ©ã‚’ã€€ã²ã‚‰ã‘ã¾ã›ã‚“ã§ã—ãŸ');
    }
  };

  const stopCamera = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop());
      streamRef.current = null;
    }
    setIsStreaming(false);
  }, []);

  const takePicture = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');

    // Crop to the tall rectangle scan box (30% width, 80% height, centered)
    const cropW = video.videoWidth * 0.3;
    const cropH = video.videoHeight * 0.8;
    const cropX = (video.videoWidth - cropW) / 2;
    const cropY = (video.videoHeight - cropH) / 2;

    canvas.width = cropW;
    canvas.height = cropH;

    // Save a color version for display
    ctx.drawImage(video, cropX, cropY, cropW, cropH, 0, 0, cropW, cropH);
    const imageUrl = canvas.toDataURL('image/png');
    setCapturedImage(imageUrl);

    // Apply filters for OCR
    ctx.filter = 'contrast(1.5) grayscale(1)';
    ctx.drawImage(video, cropX, cropY, cropW, cropH, 0, 0, cropW, cropH);
    ctx.filter = 'none';

    stopCamera();
    setIsAnalyzing(true);

    try {
      // Send image to server-side OCR with 30s timeout
      const imageData = canvas.toDataURL('image/png');
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 30000);

      const ocrRes = await fetch('/api/ocr', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ image: imageData }),
        signal: controller.signal,
      });
      clearTimeout(timeout);

      if (!ocrRes.ok) throw new Error(`OCR error: ${ocrRes.status}`);
      const { text: cleanText } = await ocrRes.json();

      if (cleanText && cleanText.length > 0) {
        const furigana = await getFurigana(cleanText);
        setResults([{ id: 1, text: cleanText, furigana }]);
      } else {
        setResults([]);
      }
    } catch (err) {
      console.error('OCR error:', err);
      if (err.name === 'AbortError') {
        setResults([{ id: 1, text: '', furigana: [], timeout: true }]);
      } else {
        setResults([]);
      }
    }

    setIsAnalyzing(false);
  }, [stopCamera]);

  const handleBack = () => {
    stopCamera();
    onBack();
  };

  useEffect(() => {
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  const allText = results.map((r) => r.text).join('');

  return (
    <div className="camera-mode">
      <div className="top-bar">
        <button className="back-btn" onClick={handleBack}>â† ã‚‚ã©ã‚‹</button>
        <h1>ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ ğŸ“·</h1>
      </div>

      {isStreaming && (
        <div className="camera-area">
          <video
            ref={videoRef}
            autoPlay
            playsInline
            className="visible zoomed"
          />
          <div className="scan-overlay">
            <div className="scan-box tall" />
          </div>
          <canvas ref={canvasRef} style={{ display: 'none' }} />
        </div>
      )}
      {!isStreaming && <canvas ref={canvasRef} style={{ display: 'none' }} />}

      {capturedImage && !isStreaming && (
        <div className="captured-crop">
          <img src={capturedImage} alt="ã¨ã£ãŸã€€ã—ã‚ƒã—ã‚“" />
        </div>
      )}

      <div className="camera-controls">
        {!isStreaming && !capturedImage && !isAnalyzing && (
          <button className="camera-start-btn" onClick={startCamera}>
            ğŸ“· ã‚«ãƒ¡ãƒ©ã‚’ã€€ã²ã‚‰ã
          </button>
        )}
        {isStreaming && (
          <>
            <button className="camera-shutter-btn" onClick={takePicture}>
              ğŸ“¸
            </button>
            <span className="shutter-hint">ãƒœã‚¿ãƒ³ã‚’ã€€ãŠã—ã¦ã€€ã—ã‚ƒã—ã‚“ã‚’ã€€ã¨ã£ã¦ã­</span>
          </>
        )}
        {capturedImage && !isAnalyzing && (
          <button className="camera-start-btn" onClick={startCamera}>
            ğŸ“· ã‚‚ã†ã„ã¡ã©ã€€ã¨ã‚‹
          </button>
        )}
      </div>

      {isAnalyzing && (
        <div className="scan-status">
          <div className="loading-spinner small" />
          <span>ã‚ˆã¿ã¨ã£ã¦ã„ã¾ã™...</span>
        </div>
      )}

      {!isAnalyzing && results.length > 0 && (
        <div className="live-results">
          {results.map((result) => (
            <div key={result.id} className="live-result-item">
              <div className="live-result-content">
                <div className="furigana-text large">
                  {result.furigana.map((item, i) => (
                    <span key={i} className="word">
                      {item.hasKanji ? (
                        <ruby>
                          {item.text}
                          <rt>{item.reading}</rt>
                        </ruby>
                      ) : (
                        item.text
                      )}
                    </span>
                  ))}
                </div>
              </div>
              <button className="speak-btn" onClick={() => speak(result.text)}>
                ğŸ”Š
              </button>
            </div>
          ))}
        </div>
      )}

      {!isAnalyzing && capturedImage && results.length > 0 && results[0].timeout && (
        <div className="results-area">
          <p className="no-results">ã˜ã‹ã‚“ãŒã€€ã‹ã‹ã‚Šã™ãã¾ã—ãŸã€‚ã‚‚ã†ã„ã¡ã©ã€€ãŸã‚ã—ã¦ã­</p>
        </div>
      )}

      {!isAnalyzing && capturedImage && results.length === 0 && (
        <div className="results-area">
          <p className="no-results">ã‹ã‚“ã˜ãŒã€€ã¿ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</p>
        </div>
      )}

      {!isAnalyzing && allText && (
        <div className="camera-controls">
          <button className="speak-btn-large" onClick={() => speak(allText)}>
            ğŸ”Š ã‚ˆã‚€
          </button>
        </div>
      )}
    </div>
  );
}
